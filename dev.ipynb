{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_creation import fc\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def build_training_data(config) -> pd.DataFrame:\n",
    "    df = pd.read_csv(config[\"training_data_path\"])\n",
    "    df.rename(columns={\"period\": \"date\"}, inplace=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    df = fc(df, config[\"time_windows\"], config[\"large_time_windows\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_time_series_ds(config) -> DataLoader:\n",
    "\n",
    "    df = build_training_data(config)\n",
    "\n",
    "    training_cutoff = round(df[\"time_idx\"].quantile(config[\"training_cutoff_quantile\"]))\n",
    "    time_varying_unknown_reals = [x for x in df.columns if \"rolling\" in x] + [config[\"target\"]]\n",
    "    print(config[\"time_varying_known_real_additions\"])\n",
    "    time_varying_known_reals = (\n",
    "        [x for x in df.columns if x.startswith(\"sin\") or x.startswith(\"cos\")]\n",
    "        + [x for x in df.columns if \"shifted\" in x]\n",
    "        + config[\"time_varying_known_real_additions\"]\n",
    "    )\n",
    "    ds_train = TimeSeriesDataSet(\n",
    "        df[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=config[\"target\"],\n",
    "        group_ids=config[\"group_ids\"],\n",
    "        max_encoder_length=config[\"max_encoder_len\"],\n",
    "        min_prediction_length=1,\n",
    "        max_prediction_length=config[\"max_pred_len\"],\n",
    "        static_categoricals=config[\"static_categoricals\"],\n",
    "        time_varying_known_reals=time_varying_known_reals,\n",
    "        time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "        target_normalizer=GroupNormalizer(groups=[\"fueltype\"], transformation=\"softplus\"),\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "    )\n",
    "    ds_val = TimeSeriesDataSet.from_dataset(\n",
    "        ds_train, df, predict=True, stop_randomization=True\n",
    "    )  # allow_missing_timesteps=True)\n",
    "\n",
    "    train_dataloader = ds_train.to_dataloader(train=True, batch_size=config[\"batch_size\"])\n",
    "    val_dataloader = ds_val.to_dataloader(train=False, batch_size=config[\"batch_size\"] * 10)\n",
    "\n",
    "    return train_dataloader, val_dataloader, ds_train\n",
    "\n",
    "\n",
    "def build_tft(config, ds_train) -> TemporalFusionTransformer:\n",
    "    trainer = pl.Trainer(**config[\"trainer_params\"])\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(ds_train, **config[\"tft_params\"])\n",
    "\n",
    "    return trainer, tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "/home/luke/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/luke/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "train_dataloader, val_dataloader, ds_train = build_time_series_ds(config)\n",
    "\n",
    "trainer, g = build_tft(config,ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"attention_head_size\":               4\n",
       "\"categorical_groups\":                {}\n",
       "\"causal_attention\":                  True\n",
       "\"dropout\":                           0.4\n",
       "\"embedding_labels\":                  {'fueltype': {'COL': 0, 'NG': 1, 'NUC': 2, 'OIL': 3, 'OTH': 4, 'SUN': 5, 'WAT': 6, 'WND': 7}}\n",
       "\"embedding_paddings\":                []\n",
       "\"embedding_sizes\":                   {'fueltype': (8, 5)}\n",
       "\"hidden_continuous_size\":            10\n",
       "\"hidden_continuous_sizes\":           {}\n",
       "\"hidden_size\":                       32\n",
       "\"learning_rate\":                     0.005\n",
       "\"log_gradient_flow\":                 False\n",
       "\"log_interval\":                      10\n",
       "\"log_val_interval\":                  10\n",
       "\"logging_metrics\":                   ModuleList(\n",
       "  (0): SMAPE()\n",
       "  (1): MAE()\n",
       "  (2): RMSE()\n",
       "  (3): MAPE()\n",
       ")\n",
       "\"loss\":                              QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98])\n",
       "\"lstm_layers\":                       1\n",
       "\"max_encoder_length\":                672\n",
       "\"monotone_constaints\":               {}\n",
       "\"optimizer\":                         Ranger\n",
       "\"optimizer_params\":                  None\n",
       "\"output_size\":                       7\n",
       "\"output_transformer\":                GroupNormalizer(\n",
       "\tmethod='standard',\n",
       "\tgroups=['fueltype'],\n",
       "\tcenter=True,\n",
       "\tscale_by_group=False,\n",
       "\ttransformation='softplus',\n",
       "\tmethod_kwargs={}\n",
       ")\n",
       "\"reduce_on_plateau_min_lr\":          1e-05\n",
       "\"reduce_on_plateau_patience\":        4\n",
       "\"reduce_on_plateau_reduction\":       2.0\n",
       "\"share_single_variable_networks\":    False\n",
       "\"static_categoricals\":               ['fueltype']\n",
       "\"static_reals\":                      ['encoder_length', 'value_center', 'value_scale']\n",
       "\"time_varying_categoricals_decoder\": []\n",
       "\"time_varying_categoricals_encoder\": []\n",
       "\"time_varying_reals_decoder\":        ['sin_hour', 'cos_hour', 'sin_day_week', 'cos_day_week', 'sin_day_of_year', 'cos_day_of_year', 'sin_week_year', 'cos_week_year', 'sin_month', 'cos_month', 'sin_quarter', 'cos_quarter', 'shifted_24', 'shifted_48', 'shifted_168', 'shifted_730', 'shifted_8760', 'year', 'relative_time_idx']\n",
       "\"time_varying_reals_encoder\":        ['sin_hour', 'cos_hour', 'sin_day_week', 'cos_day_week', 'sin_day_of_year', 'cos_day_of_year', 'sin_week_year', 'cos_week_year', 'sin_month', 'cos_month', 'sin_quarter', 'cos_quarter', 'shifted_24', 'shifted_48', 'shifted_168', 'shifted_730', 'shifted_8760', 'year', 'relative_time_idx', 'rolling_date_mean_2', 'rolling_date_std_2', 'rolling_date_mean_4', 'rolling_date_std_4', 'rolling_date_mean_6', 'rolling_date_std_6', 'rolling_date_mean_12', 'rolling_date_std_12', 'rolling_type_mean_2', 'rolling_type_std_2', 'rolling_type_mean_4', 'rolling_type_std_4', 'rolling_type_mean_6', 'rolling_type_std_6', 'rolling_type_mean_12', 'rolling_type_std_12', 'value']\n",
       "\"weight_decay\":                      0.0\n",
       "\"x_categoricals\":                    ['fueltype']\n",
       "\"x_reals\":                           ['encoder_length', 'value_center', 'value_scale', 'sin_hour', 'cos_hour', 'sin_day_week', 'cos_day_week', 'sin_day_of_year', 'cos_day_of_year', 'sin_week_year', 'cos_week_year', 'sin_month', 'cos_month', 'sin_quarter', 'cos_quarter', 'shifted_24', 'shifted_48', 'shifted_168', 'shifted_730', 'shifted_8760', 'year', 'relative_time_idx', 'rolling_date_mean_2', 'rolling_date_std_2', 'rolling_date_mean_4', 'rolling_date_std_4', 'rolling_date_mean_6', 'rolling_date_std_6', 'rolling_date_mean_12', 'rolling_date_std_12', 'rolling_type_mean_2', 'rolling_type_std_2', 'rolling_type_mean_4', 'rolling_type_std_4', 'rolling_type_mean_6', 'rolling_type_std_6', 'rolling_type_mean_12', 'rolling_type_std_12', 'value']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find difference between BaseModel and BaseModelWithCovariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import BaseModel, BaseModelWithCovariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_attrs = set(dir(BaseModel))\n",
    "cov_attrs = set(dir(BaseModelWithCovariates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CHECKPOINT_HYPER_PARAMS_KEY',\n",
       " 'CHECKPOINT_HYPER_PARAMS_NAME',\n",
       " 'CHECKPOINT_HYPER_PARAMS_SPECIAL_KEY',\n",
       " 'CHECKPOINT_HYPER_PARAMS_TYPE',\n",
       " 'T_destination',\n",
       " '_LightningModule__check_allowed',\n",
       " '_LightningModule__check_not_nested',\n",
       " '_LightningModule__to_tensor',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__jit_unused_properties__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_apply_batch_transfer_handler',\n",
       " '_call_batch_hook',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_jit_is_scripting',\n",
       " '_load_from_state_dict',\n",
       " '_log_dict_through_fabric',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_named_members',\n",
       " '_on_before_batch_transfer',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_sharded_tensor_state_dict_hooks_if_available',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_set_hparams',\n",
       " '_slow_forward',\n",
       " '_to_hparams_dict',\n",
       " '_verify_is_manual_optimization',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'all_gather',\n",
       " 'apply',\n",
       " 'automatic_optimization',\n",
       " 'backward',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'clip_gradients',\n",
       " 'compile',\n",
       " 'configure_callbacks',\n",
       " 'configure_gradient_clipping',\n",
       " 'configure_model',\n",
       " 'configure_optimizers',\n",
       " 'configure_sharded_model',\n",
       " 'cpu',\n",
       " 'create_log',\n",
       " 'cuda',\n",
       " 'current_epoch',\n",
       " 'current_stage',\n",
       " 'deduce_default_output_parameters',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'example_input_array',\n",
       " 'extra_repr',\n",
       " 'fabric',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'freeze',\n",
       " 'from_dataset',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'global_rank',\n",
       " 'global_step',\n",
       " 'half',\n",
       " 'hparams',\n",
       " 'hparams_initial',\n",
       " 'ipu',\n",
       " 'load_from_checkpoint',\n",
       " 'load_state_dict',\n",
       " 'local_rank',\n",
       " 'log',\n",
       " 'log_dict',\n",
       " 'log_gradient_flow',\n",
       " 'log_interval',\n",
       " 'log_metrics',\n",
       " 'log_prediction',\n",
       " 'logger',\n",
       " 'loggers',\n",
       " 'lr_scheduler_step',\n",
       " 'lr_schedulers',\n",
       " 'manual_backward',\n",
       " 'modules',\n",
       " 'n_targets',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'on_after_backward',\n",
       " 'on_after_batch_transfer',\n",
       " 'on_before_backward',\n",
       " 'on_before_batch_transfer',\n",
       " 'on_before_optimizer_step',\n",
       " 'on_before_zero_grad',\n",
       " 'on_epoch_end',\n",
       " 'on_fit_end',\n",
       " 'on_fit_start',\n",
       " 'on_gpu',\n",
       " 'on_load_checkpoint',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_batch_start',\n",
       " 'on_predict_end',\n",
       " 'on_predict_epoch_end',\n",
       " 'on_predict_epoch_start',\n",
       " 'on_predict_model_eval',\n",
       " 'on_predict_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_batch_start',\n",
       " 'on_test_end',\n",
       " 'on_test_epoch_end',\n",
       " 'on_test_epoch_start',\n",
       " 'on_test_model_eval',\n",
       " 'on_test_model_train',\n",
       " 'on_test_start',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_batch_start',\n",
       " 'on_train_end',\n",
       " 'on_train_epoch_end',\n",
       " 'on_train_epoch_start',\n",
       " 'on_train_start',\n",
       " 'on_validation_batch_end',\n",
       " 'on_validation_batch_start',\n",
       " 'on_validation_end',\n",
       " 'on_validation_epoch_end',\n",
       " 'on_validation_epoch_start',\n",
       " 'on_validation_model_eval',\n",
       " 'on_validation_model_train',\n",
       " 'on_validation_model_zero_grad',\n",
       " 'on_validation_start',\n",
       " 'optimizer_step',\n",
       " 'optimizer_zero_grad',\n",
       " 'optimizers',\n",
       " 'parameters',\n",
       " 'plot_prediction',\n",
       " 'predict',\n",
       " 'predict_dataloader',\n",
       " 'predict_dependency',\n",
       " 'predict_step',\n",
       " 'predicting',\n",
       " 'prepare_data',\n",
       " 'print',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'save_hyperparameters',\n",
       " 'set_extra_state',\n",
       " 'setup',\n",
       " 'share_memory',\n",
       " 'size',\n",
       " 'state_dict',\n",
       " 'step',\n",
       " 'target_names',\n",
       " 'teardown',\n",
       " 'test_dataloader',\n",
       " 'test_step',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'to_network_output',\n",
       " 'to_onnx',\n",
       " 'to_prediction',\n",
       " 'to_quantiles',\n",
       " 'to_torchscript',\n",
       " 'toggle_optimizer',\n",
       " 'train',\n",
       " 'train_dataloader',\n",
       " 'trainer',\n",
       " 'training_step',\n",
       " 'transfer_batch_to_device',\n",
       " 'transform_output',\n",
       " 'type',\n",
       " 'unfreeze',\n",
       " 'untoggle_optimizer',\n",
       " 'val_dataloader',\n",
       " 'validation_step',\n",
       " 'xpu',\n",
       " 'zero_grad'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CHECKPOINT_HYPER_PARAMS_KEY',\n",
       " 'CHECKPOINT_HYPER_PARAMS_NAME',\n",
       " 'CHECKPOINT_HYPER_PARAMS_SPECIAL_KEY',\n",
       " 'CHECKPOINT_HYPER_PARAMS_TYPE',\n",
       " 'T_destination',\n",
       " '_LightningModule__check_allowed',\n",
       " '_LightningModule__check_not_nested',\n",
       " '_LightningModule__to_tensor',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__jit_unused_properties__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_apply_batch_transfer_handler',\n",
       " '_call_batch_hook',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_jit_is_scripting',\n",
       " '_load_from_state_dict',\n",
       " '_log_dict_through_fabric',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_named_members',\n",
       " '_on_before_batch_transfer',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_sharded_tensor_state_dict_hooks_if_available',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_set_hparams',\n",
       " '_slow_forward',\n",
       " '_to_hparams_dict',\n",
       " '_verify_is_manual_optimization',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'all_gather',\n",
       " 'apply',\n",
       " 'automatic_optimization',\n",
       " 'backward',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'calculate_prediction_actual_by_variable',\n",
       " 'call_super_init',\n",
       " 'categorical_groups_mapping',\n",
       " 'categoricals',\n",
       " 'children',\n",
       " 'clip_gradients',\n",
       " 'compile',\n",
       " 'configure_callbacks',\n",
       " 'configure_gradient_clipping',\n",
       " 'configure_model',\n",
       " 'configure_optimizers',\n",
       " 'configure_sharded_model',\n",
       " 'cpu',\n",
       " 'create_log',\n",
       " 'cuda',\n",
       " 'current_epoch',\n",
       " 'current_stage',\n",
       " 'decoder_variables',\n",
       " 'deduce_default_output_parameters',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dump_patches',\n",
       " 'encoder_variables',\n",
       " 'eval',\n",
       " 'example_input_array',\n",
       " 'extra_repr',\n",
       " 'extract_features',\n",
       " 'fabric',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'freeze',\n",
       " 'from_dataset',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'global_rank',\n",
       " 'global_step',\n",
       " 'half',\n",
       " 'hparams',\n",
       " 'hparams_initial',\n",
       " 'ipu',\n",
       " 'load_from_checkpoint',\n",
       " 'load_state_dict',\n",
       " 'local_rank',\n",
       " 'log',\n",
       " 'log_dict',\n",
       " 'log_gradient_flow',\n",
       " 'log_interval',\n",
       " 'log_metrics',\n",
       " 'log_prediction',\n",
       " 'logger',\n",
       " 'loggers',\n",
       " 'lr_scheduler_step',\n",
       " 'lr_schedulers',\n",
       " 'manual_backward',\n",
       " 'modules',\n",
       " 'n_targets',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'on_after_backward',\n",
       " 'on_after_batch_transfer',\n",
       " 'on_before_backward',\n",
       " 'on_before_batch_transfer',\n",
       " 'on_before_optimizer_step',\n",
       " 'on_before_zero_grad',\n",
       " 'on_epoch_end',\n",
       " 'on_fit_end',\n",
       " 'on_fit_start',\n",
       " 'on_gpu',\n",
       " 'on_load_checkpoint',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_batch_start',\n",
       " 'on_predict_end',\n",
       " 'on_predict_epoch_end',\n",
       " 'on_predict_epoch_start',\n",
       " 'on_predict_model_eval',\n",
       " 'on_predict_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_batch_start',\n",
       " 'on_test_end',\n",
       " 'on_test_epoch_end',\n",
       " 'on_test_epoch_start',\n",
       " 'on_test_model_eval',\n",
       " 'on_test_model_train',\n",
       " 'on_test_start',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_batch_start',\n",
       " 'on_train_end',\n",
       " 'on_train_epoch_end',\n",
       " 'on_train_epoch_start',\n",
       " 'on_train_start',\n",
       " 'on_validation_batch_end',\n",
       " 'on_validation_batch_start',\n",
       " 'on_validation_end',\n",
       " 'on_validation_epoch_end',\n",
       " 'on_validation_epoch_start',\n",
       " 'on_validation_model_eval',\n",
       " 'on_validation_model_train',\n",
       " 'on_validation_model_zero_grad',\n",
       " 'on_validation_start',\n",
       " 'optimizer_step',\n",
       " 'optimizer_zero_grad',\n",
       " 'optimizers',\n",
       " 'parameters',\n",
       " 'plot_prediction',\n",
       " 'plot_prediction_actual_by_variable',\n",
       " 'predict',\n",
       " 'predict_dataloader',\n",
       " 'predict_dependency',\n",
       " 'predict_step',\n",
       " 'predicting',\n",
       " 'prepare_data',\n",
       " 'print',\n",
       " 'reals',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'save_hyperparameters',\n",
       " 'set_extra_state',\n",
       " 'setup',\n",
       " 'share_memory',\n",
       " 'size',\n",
       " 'state_dict',\n",
       " 'static_variables',\n",
       " 'step',\n",
       " 'target_names',\n",
       " 'target_positions',\n",
       " 'teardown',\n",
       " 'test_dataloader',\n",
       " 'test_step',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'to_network_output',\n",
       " 'to_onnx',\n",
       " 'to_prediction',\n",
       " 'to_quantiles',\n",
       " 'to_torchscript',\n",
       " 'toggle_optimizer',\n",
       " 'train',\n",
       " 'train_dataloader',\n",
       " 'trainer',\n",
       " 'training_step',\n",
       " 'transfer_batch_to_device',\n",
       " 'transform_output',\n",
       " 'type',\n",
       " 'unfreeze',\n",
       " 'untoggle_optimizer',\n",
       " 'val_dataloader',\n",
       " 'validation_step',\n",
       " 'xpu',\n",
       " 'zero_grad'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_attrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_custom_attrs = {attr for attr in base_attrs if not attr.startswith(\"__\") and not attr.endswith(\"__\")}\n",
    "covariate_custom_attrs = {attr for attr in cov_attrs if not attr.startswith(\"__\") and not attr.endswith(\"__\")}\n",
    "\n",
    "# Identify attributes and methods unique to BaseModelWithCovariates\n",
    "unique_to_covariate = covariate_custom_attrs - base_custom_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'calculate_prediction_actual_by_variable',\n",
       " 'categorical_groups_mapping',\n",
       " 'categoricals',\n",
       " 'decoder_variables',\n",
       " 'encoder_variables',\n",
       " 'extract_features',\n",
       " 'plot_prediction_actual_by_variable',\n",
       " 'reals',\n",
       " 'static_variables',\n",
       " 'target_positions'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_to_covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "/home/luke/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/luke/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "from model import build_time_series_ds, build_tft\n",
    "from config import get_config\n",
    "\n",
    "cfg = get_config()\n",
    "\n",
    "train_dataloader, val_dataloader, ds_train = build_time_series_ds(cfg)\n",
    "trainer, tft = build_tft(cfg, ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder_length', 'value_center', 'value_scale']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.static_reals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tft.hparams.hidden_continuous_sizes.get(\"value_center\", tft.hparams.hidden_continuous_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in mytft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/luke/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "from tft import MyTemporalFusionTransformer\n",
    "from config import get_config\n",
    "from model import build_training_data, build_time_series_ds\n",
    "\n",
    "#import torch\n",
    "\n",
    "#from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "\n",
    "config = get_config()\n",
    "df, training_cutoff, time_varying_unknown_reals, time_varying_known_reals = build_training_data(config)\n",
    "\n",
    "train_dataloader, val_dataloader,ds_train = build_time_series_ds(config)\n",
    "\n",
    "\"\"\"\n",
    "r = TemporalFusionTransformer( \n",
    "    max_encoder_length=config[\"max_encoder_len\"],\n",
    "    static_categoricals=config[\"static_categoricals\"],\n",
    "    static_reals=config[\"static_reals\"],\n",
    "    time_varying_reals_encoder=time_varying_known_reals + time_varying_unknown_reals,\n",
    "    time_varying_reals_decoder=time_varying_known_reals,\n",
    "    x_reals=config[\"static_reals\"] + time_varying_known_reals + time_varying_unknown_reals,\n",
    "    x_categoricals=config[\"group_ids\"],\n",
    "    **config[\"tft_params\"]\n",
    ")\n",
    "\"\"\"\n",
    "t = MyTemporalFusionTransformer(\n",
    "    max_encoder_length=config[\"max_encoder_len\"],\n",
    "    static_categoricals=config[\"static_categoricals\"],\n",
    "    static_reals=config[\"static_reals\"],\n",
    "    time_varying_reals_encoder=time_varying_known_reals + time_varying_unknown_reals,\n",
    "    time_varying_reals_decoder=time_varying_known_reals,\n",
    "    x_reals=config[\"static_reals\"] + time_varying_known_reals + time_varying_unknown_reals,\n",
    "    x_categoricals=config[\"group_ids\"],\n",
    "    **config[\"tft_params\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = next(iter(train_dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_cat torch.Size([128, 672, 1])\n",
      "encoder_cont torch.Size([128, 672, 41])\n",
      "encoder_target torch.Size([128, 672])\n",
      "encoder_lengths torch.Size([128])\n",
      "decoder_cat torch.Size([128, 168, 1])\n",
      "decoder_cont torch.Size([128, 168, 41])\n",
      "decoder_target torch.Size([128, 168])\n",
      "decoder_lengths torch.Size([128])\n",
      "decoder_time_idx torch.Size([128, 168])\n",
      "groups torch.Size([128, 1])\n",
      "target_scale torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "for k in i:\n",
    "    print(k, i[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'static_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic_variables\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'static_variables'"
     ]
    }
   ],
   "source": [
    "i[\"static_variables\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of static variables: 4\n",
      "embeddings_varying_encoder shape: torch.Size([128, 672, 32])\n",
      "embeddings_varying_decoder shape: torch.Size([128, 168, 32])\n",
      "static_embedding shape: torch.Size([128, 32])\n",
      "lstm_output_encoder shape: torch.Size([128, 672, 32])\n",
      "lstm_output_decoder shape: torch.Size([128, 168, 32])\n",
      "lstm_output shape: torch.Size([128, 840, 32])\n",
      "torch.Size([128, 32])\n",
      "tensor([[ 0.0327,  0.3122,  0.8833,  ...,  0.1788,  0.1305, -1.1699],\n",
      "        [ 0.3069,  0.3290,  0.3416,  ...,  0.3487, -0.3320, -0.5694],\n",
      "        [ 0.3516,  0.4481,  0.3561,  ..., -0.3984,  0.0294, -0.7366],\n",
      "        ...,\n",
      "        [ 0.2319,  0.5471,  0.4556,  ..., -0.4400, -0.5103, -0.6819],\n",
      "        [ 0.4475,  1.0339,  0.5467,  ..., -0.0525, -0.5057, -0.7574],\n",
      "        [ 0.6230,  0.6082,  0.1276,  ...,  0.9015,  0.6393,  0.4197]],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out = t(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6887, 0.1725, 0.0453, 0.0935]],\n",
       "\n",
       "        [[0.0535, 0.3311, 0.0671, 0.5482]],\n",
       "\n",
       "        [[0.0433, 0.4755, 0.0912, 0.3900]],\n",
       "\n",
       "        [[0.0382, 0.4303, 0.1190, 0.4124]],\n",
       "\n",
       "        [[0.6485, 0.1619, 0.0384, 0.1513]],\n",
       "\n",
       "        [[0.2556, 0.1643, 0.0352, 0.5449]],\n",
       "\n",
       "        [[0.6887, 0.1725, 0.0453, 0.0935]],\n",
       "\n",
       "        [[0.7048, 0.1209, 0.0433, 0.1310]],\n",
       "\n",
       "        [[0.2556, 0.1643, 0.0352, 0.5449]],\n",
       "\n",
       "        [[0.2736, 0.1757, 0.0345, 0.5162]],\n",
       "\n",
       "        [[0.3444, 0.1978, 0.0334, 0.4244]],\n",
       "\n",
       "        [[0.6741, 0.1217, 0.0408, 0.1633]],\n",
       "\n",
       "        [[0.1495, 0.1775, 0.0378, 0.6352]],\n",
       "\n",
       "        [[0.7656, 0.0831, 0.0635, 0.0878]],\n",
       "\n",
       "        [[0.0482, 0.3249, 0.0771, 0.5499]],\n",
       "\n",
       "        [[0.0884, 0.5565, 0.0442, 0.3108]],\n",
       "\n",
       "        [[0.1327, 0.2891, 0.0371, 0.5412]],\n",
       "\n",
       "        [[0.2569, 0.0936, 0.0432, 0.6063]],\n",
       "\n",
       "        [[0.0623, 0.4770, 0.0571, 0.4036]],\n",
       "\n",
       "        [[0.6443, 0.1589, 0.0381, 0.1587]],\n",
       "\n",
       "        [[0.6871, 0.1500, 0.0417, 0.1211]],\n",
       "\n",
       "        [[0.0930, 0.5599, 0.0430, 0.3040]],\n",
       "\n",
       "        [[0.0375, 0.4043, 0.1254, 0.4328]],\n",
       "\n",
       "        [[0.0436, 0.4561, 0.0903, 0.4101]],\n",
       "\n",
       "        [[0.6421, 0.1990, 0.0398, 0.1190]],\n",
       "\n",
       "        [[0.1495, 0.1775, 0.0378, 0.6352]],\n",
       "\n",
       "        [[0.2711, 0.1812, 0.0344, 0.5134]],\n",
       "\n",
       "        [[0.0625, 0.4627, 0.0570, 0.4179]],\n",
       "\n",
       "        [[0.1685, 0.2059, 0.0359, 0.5897]],\n",
       "\n",
       "        [[0.0884, 0.5565, 0.0442, 0.3108]],\n",
       "\n",
       "        [[0.6485, 0.1619, 0.0384, 0.1513]],\n",
       "\n",
       "        [[0.3419, 0.1889, 0.0337, 0.4355]],\n",
       "\n",
       "        [[0.0543, 0.3582, 0.0659, 0.5216]],\n",
       "\n",
       "        [[0.6433, 0.1583, 0.0380, 0.1604]],\n",
       "\n",
       "        [[0.7317, 0.0761, 0.0544, 0.1379]],\n",
       "\n",
       "        [[0.3444, 0.1978, 0.0334, 0.4244]],\n",
       "\n",
       "        [[0.0930, 0.5599, 0.0430, 0.3040]],\n",
       "\n",
       "        [[0.7157, 0.1498, 0.0492, 0.0853]],\n",
       "\n",
       "        [[0.2711, 0.1812, 0.0344, 0.5134]],\n",
       "\n",
       "        [[0.2382, 0.2711, 0.0329, 0.4577]],\n",
       "\n",
       "        [[0.0589, 0.4694, 0.0603, 0.4114]],\n",
       "\n",
       "        [[0.6340, 0.1822, 0.0378, 0.1460]],\n",
       "\n",
       "        [[0.3028, 0.1113, 0.0395, 0.5464]],\n",
       "\n",
       "        [[0.0482, 0.3249, 0.0771, 0.5499]],\n",
       "\n",
       "        [[0.7064, 0.1253, 0.0435, 0.1248]],\n",
       "\n",
       "        [[0.5964, 0.1898, 0.0359, 0.1778]],\n",
       "\n",
       "        [[0.0535, 0.3311, 0.0671, 0.5482]],\n",
       "\n",
       "        [[0.1495, 0.1775, 0.0378, 0.6352]],\n",
       "\n",
       "        [[0.2382, 0.2711, 0.0329, 0.4577]],\n",
       "\n",
       "        [[0.5697, 0.1726, 0.0353, 0.2224]],\n",
       "\n",
       "        [[0.2005, 0.1554, 0.0367, 0.6074]],\n",
       "\n",
       "        [[0.6519, 0.1653, 0.0387, 0.1441]],\n",
       "\n",
       "        [[0.0613, 0.4138, 0.0579, 0.4669]],\n",
       "\n",
       "        [[0.6710, 0.1773, 0.0418, 0.1098]],\n",
       "\n",
       "        [[0.6871, 0.1082, 0.0428, 0.1619]],\n",
       "\n",
       "        [[0.7154, 0.1295, 0.0451, 0.1100]],\n",
       "\n",
       "        [[0.3375, 0.2068, 0.0332, 0.4224]],\n",
       "\n",
       "        [[0.2556, 0.1643, 0.0352, 0.5449]],\n",
       "\n",
       "        [[0.0629, 0.4254, 0.0566, 0.4551]],\n",
       "\n",
       "        [[0.2023, 0.1590, 0.0364, 0.6023]],\n",
       "\n",
       "        [[0.2186, 0.0704, 0.0526, 0.6583]],\n",
       "\n",
       "        [[0.3115, 0.1075, 0.0401, 0.5409]],\n",
       "\n",
       "        [[0.2402, 0.1539, 0.0360, 0.5700]],\n",
       "\n",
       "        [[0.7181, 0.1266, 0.0455, 0.1099]],\n",
       "\n",
       "        [[0.1920, 0.3261, 0.0336, 0.4482]],\n",
       "\n",
       "        [[0.6519, 0.1653, 0.0387, 0.1441]],\n",
       "\n",
       "        [[0.7249, 0.1192, 0.0465, 0.1093]],\n",
       "\n",
       "        [[0.6873, 0.1495, 0.0417, 0.1215]],\n",
       "\n",
       "        [[0.2643, 0.1536, 0.0357, 0.5464]],\n",
       "\n",
       "        [[0.2621, 0.1607, 0.0354, 0.5418]],\n",
       "\n",
       "        [[0.2406, 0.1585, 0.0357, 0.5652]],\n",
       "\n",
       "        [[0.3239, 0.2047, 0.0333, 0.4381]],\n",
       "\n",
       "        [[0.7691, 0.0700, 0.0841, 0.0768]],\n",
       "\n",
       "        [[0.7317, 0.0761, 0.0544, 0.1379]],\n",
       "\n",
       "        [[0.6421, 0.1990, 0.0398, 0.1190]],\n",
       "\n",
       "        [[0.7630, 0.0881, 0.0607, 0.0882]],\n",
       "\n",
       "        [[0.7048, 0.1209, 0.0433, 0.1310]],\n",
       "\n",
       "        [[0.6443, 0.1589, 0.0381, 0.1587]],\n",
       "\n",
       "        [[0.0964, 0.5608, 0.0422, 0.3006]],\n",
       "\n",
       "        [[0.1595, 0.2800, 0.0353, 0.5252]],\n",
       "\n",
       "        [[0.7483, 0.1029, 0.0527, 0.0961]],\n",
       "\n",
       "        [[0.1825, 0.1321, 0.0389, 0.6464]],\n",
       "\n",
       "        [[0.2549, 0.1711, 0.0349, 0.5391]],\n",
       "\n",
       "        [[0.7691, 0.0700, 0.0841, 0.0768]],\n",
       "\n",
       "        [[0.7674, 0.0659, 0.0848, 0.0818]],\n",
       "\n",
       "        [[0.6871, 0.1082, 0.0428, 0.1619]],\n",
       "\n",
       "        [[0.1408, 0.0957, 0.0469, 0.7166]],\n",
       "\n",
       "        [[0.0571, 0.3715, 0.0623, 0.5091]],\n",
       "\n",
       "        [[0.5649, 0.1704, 0.0353, 0.2294]],\n",
       "\n",
       "        [[0.6004, 0.1891, 0.0361, 0.1744]],\n",
       "\n",
       "        [[0.1408, 0.0957, 0.0469, 0.7166]],\n",
       "\n",
       "        [[0.2106, 0.3093, 0.0332, 0.4469]],\n",
       "\n",
       "        [[0.6211, 0.1335, 0.0381, 0.2073]],\n",
       "\n",
       "        [[0.0924, 0.5556, 0.0432, 0.3088]],\n",
       "\n",
       "        [[0.0508, 0.3159, 0.0716, 0.5616]],\n",
       "\n",
       "        [[0.1049, 0.2292, 0.0412, 0.6246]],\n",
       "\n",
       "        [[0.6887, 0.1725, 0.0453, 0.0935]],\n",
       "\n",
       "        [[0.0623, 0.4770, 0.0571, 0.4036]],\n",
       "\n",
       "        [[0.6748, 0.1505, 0.0403, 0.1345]],\n",
       "\n",
       "        [[0.6443, 0.1589, 0.0381, 0.1587]],\n",
       "\n",
       "        [[0.1685, 0.2059, 0.0359, 0.5897]],\n",
       "\n",
       "        [[0.6871, 0.1500, 0.0417, 0.1211]],\n",
       "\n",
       "        [[0.0589, 0.4694, 0.0603, 0.4114]],\n",
       "\n",
       "        [[0.0477, 0.3903, 0.0781, 0.4840]],\n",
       "\n",
       "        [[0.1770, 0.1292, 0.0394, 0.6544]],\n",
       "\n",
       "        [[0.7674, 0.0659, 0.0848, 0.0818]],\n",
       "\n",
       "        [[0.0884, 0.5565, 0.0442, 0.3108]],\n",
       "\n",
       "        [[0.2402, 0.1539, 0.0360, 0.5700]],\n",
       "\n",
       "        [[0.2711, 0.1812, 0.0344, 0.5134]],\n",
       "\n",
       "        [[0.0783, 0.7172, 0.0517, 0.1528]],\n",
       "\n",
       "        [[0.3444, 0.1978, 0.0334, 0.4244]],\n",
       "\n",
       "        [[0.0436, 0.3010, 0.0907, 0.5646]],\n",
       "\n",
       "        [[0.1327, 0.2891, 0.0371, 0.5412]],\n",
       "\n",
       "        [[0.0942, 0.6903, 0.0452, 0.1702]],\n",
       "\n",
       "        [[0.2519, 0.0969, 0.0425, 0.6086]],\n",
       "\n",
       "        [[0.0613, 0.4138, 0.0579, 0.4669]],\n",
       "\n",
       "        [[0.0589, 0.4694, 0.0603, 0.4114]],\n",
       "\n",
       "        [[0.0504, 0.4077, 0.0722, 0.4697]],\n",
       "\n",
       "        [[0.0622, 0.4909, 0.0572, 0.3897]],\n",
       "\n",
       "        [[0.6710, 0.1773, 0.0418, 0.1098]],\n",
       "\n",
       "        [[0.6890, 0.1023, 0.0437, 0.1650]],\n",
       "\n",
       "        [[0.7181, 0.1266, 0.0455, 0.1099]],\n",
       "\n",
       "        [[0.7317, 0.0761, 0.0544, 0.1379]],\n",
       "\n",
       "        [[0.3540, 0.1878, 0.0337, 0.4245]],\n",
       "\n",
       "        [[0.0589, 0.4694, 0.0603, 0.4114]],\n",
       "\n",
       "        [[0.7295, 0.0814, 0.0519, 0.1371]],\n",
       "\n",
       "        [[0.2005, 0.1554, 0.0367, 0.6074]],\n",
       "\n",
       "        [[0.6334, 0.1821, 0.0378, 0.1467]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.static_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_cat torch.Size([128, 672, 1])\n",
      "encoder_cont torch.Size([128, 672, 39])\n",
      "encoder_target torch.Size([128, 672])\n",
      "encoder_lengths torch.Size([128])\n",
      "decoder_cat torch.Size([128, 168, 1])\n",
      "decoder_cont torch.Size([128, 168, 39])\n",
      "decoder_target torch.Size([128, 168])\n",
      "decoder_lengths torch.Size([128])\n",
      "decoder_time_idx torch.Size([128, 168])\n",
      "groups torch.Size([128, 1])\n",
      "target_scale torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "for key in i.keys():\n",
    "    print(key, i[key].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tft import MyMultiEmbedding\n",
    "\n",
    "input_embeddings = MyMultiEmbedding(\n",
    "    embedding_sizes=t.hparams.embedding_sizes,\n",
    "    categorical_groups=t.hparams.categorical_groups,\n",
    "    embedding_paddings=t.hparams.embedding_paddings,\n",
    "    x_categoricals=t.hparams.x_categoricals,\n",
    "    max_embedding_size=t.hparams.hidden_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 840, 1])\n"
     ]
    }
   ],
   "source": [
    "x_cat = torch.cat([i[\"encoder_cat\"], i[\"decoder_cat\"]], dim=1)\n",
    "print(x_cat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fueltype'])\n"
     ]
    }
   ],
   "source": [
    "input_vectors = input_embeddings(x_cat)\n",
    "print(input_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 840, 39])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cont = torch.cat([i[\"encoder_cont\"], i[\"decoder_cont\"]], dim=1)\n",
    "x_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors.update(\n",
    "    {name: x_cont[..., idx].unsqueeze(-1) for idx, name in enumerate(t.hparams.x_reals) if name in t.reals}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fueltype torch.Size([128, 840, 5])\n",
      "encoder_length torch.Size([128, 840, 1])\n",
      "value_center torch.Size([128, 840, 1])\n",
      "value_scale torch.Size([128, 840, 1])\n",
      "sin_hour torch.Size([128, 840, 1])\n",
      "cos_hour torch.Size([128, 840, 1])\n",
      "sin_day_week torch.Size([128, 840, 1])\n",
      "cos_day_week torch.Size([128, 840, 1])\n",
      "sin_day_of_year torch.Size([128, 840, 1])\n",
      "cos_day_of_year torch.Size([128, 840, 1])\n",
      "sin_week_year torch.Size([128, 840, 1])\n",
      "cos_week_year torch.Size([128, 840, 1])\n",
      "sin_month torch.Size([128, 840, 1])\n",
      "cos_month torch.Size([128, 840, 1])\n",
      "sin_quarter torch.Size([128, 840, 1])\n",
      "cos_quarter torch.Size([128, 840, 1])\n",
      "shifted_24 torch.Size([128, 840, 1])\n",
      "shifted_48 torch.Size([128, 840, 1])\n",
      "shifted_168 torch.Size([128, 840, 1])\n",
      "shifted_730 torch.Size([128, 840, 1])\n",
      "shifted_8760 torch.Size([128, 840, 1])\n",
      "year torch.Size([128, 840, 1])\n",
      "rolling_date_mean_2 torch.Size([128, 840, 1])\n",
      "rolling_date_std_2 torch.Size([128, 840, 1])\n",
      "rolling_date_mean_4 torch.Size([128, 840, 1])\n",
      "rolling_date_std_4 torch.Size([128, 840, 1])\n",
      "rolling_date_mean_6 torch.Size([128, 840, 1])\n",
      "rolling_date_std_6 torch.Size([128, 840, 1])\n",
      "rolling_date_mean_12 torch.Size([128, 840, 1])\n",
      "rolling_date_std_12 torch.Size([128, 840, 1])\n",
      "rolling_type_mean_2 torch.Size([128, 840, 1])\n",
      "rolling_type_std_2 torch.Size([128, 840, 1])\n",
      "rolling_type_mean_4 torch.Size([128, 840, 1])\n",
      "rolling_type_std_4 torch.Size([128, 840, 1])\n",
      "rolling_type_mean_6 torch.Size([128, 840, 1])\n",
      "rolling_type_std_6 torch.Size([128, 840, 1])\n",
      "rolling_type_mean_12 torch.Size([128, 840, 1])\n",
      "rolling_type_std_12 torch.Size([128, 840, 1])\n",
      "value torch.Size([128, 840, 1])\n"
     ]
    }
   ],
   "source": [
    "for k in input_vectors.keys():\n",
    "    print(k,input_vectors[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fueltype', 'encoder_length', 'value_center', 'value_scale']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.static_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction torch.Size([128, 168, 7])\n",
      "encoder_attention torch.Size([128, 168, 4, 672])\n",
      "decoder_attention torch.Size([128, 168, 4, 168])\n",
      "static_variables torch.Size([128, 1, 4])\n",
      "encoder_variables torch.Size([128, 672, 1, 35])\n",
      "encoder_lengths torch.Size([128])\n",
      "decoder_lengths torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "o = t(i)\n",
    "\n",
    "for key in o.keys():\n",
    "    print(key,o[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "exp_logits = np.exp(logits)\n",
    "probabilities = exp_logits / np.sum(exp_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.3890561 , 2.71828183, 1.10517092])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65900114, 0.24243297, 0.09856589])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
